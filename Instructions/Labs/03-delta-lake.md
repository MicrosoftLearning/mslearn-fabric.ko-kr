---
lab:
  title: Apache Sparkμ—μ„ λΈνƒ€ ν…μ΄λΈ” μ‚¬μ©
  module: Work with Delta Lake tables in Microsoft Fabric
---

# Apache Sparkμ—μ„ λΈνƒ€ ν…μ΄λΈ” μ‚¬μ©

Microsoft Fabric λ μ΄ν¬ν•μ°μ¤μ ν…μ΄λΈ”μ€ μ¤ν” μ†μ¤ Delta Lake ν•μ‹μ„ κΈ°λ°μΌλ΅ ν•©λ‹λ‹¤. Delta Lakeλ” μΌκ΄„ μ²λ¦¬ λ° μ¤νΈλ¦¬λ° λ°μ΄ν„° λ¨λ‘μ— λ€ν•μ—¬ κ΄€κ³„ν• μλ―Έ μ²΄κ³„ μ§€μ›μ„ μ¶”κ°€ν•©λ‹λ‹¤. μ΄ μ—°μµμ—μ„λ” λΈνƒ€ ν…μ΄λΈ”μ„ λ§λ“¤κ³  SQL μΏΌλ¦¬λ¥Ό μ‚¬μ©ν•μ—¬ λ°μ΄ν„°λ¥Ό νƒμƒ‰ν•©λ‹λ‹¤.

μ΄ μ—°μµμ„ μ™„λ£ν•λ” λ° μ•½ **45**λ¶„ μ •λ„ μ†μ”λ©λ‹λ‹¤.

> [!NOTE]
> μ΄ μ—°μµμ„ μ™„λ£ν•λ ¤λ©΄ [Microsoft Fabric](/fabric/get-started/fabric-trial) ν‰κ°€νμ΄ ν•„μ”ν•©λ‹λ‹¤.

## μ‘μ—… μμ—­ λ§λ“¤κΈ°

λ¨Όμ € *Fabric ν‰κ°€ν*μ„ μ‚¬μ©ν•λ„λ΅ μ„¤μ •λ μ‘μ—… μμ—­μ„ λ§λ“­λ‹λ‹¤.

1. Microsoft Fabric ν™νμ΄μ§€(https://app.fabric.microsoft.com)μ—μ„ **Synapse λ°μ΄ν„° μ—”μ§€λ‹μ–΄λ§** ν™κ²½μ„ μ„ νƒν•©λ‹λ‹¤.
1. μ™Όμ½ λ©”λ‰΄ λ¨μμ—μ„ **μ‘μ—… μμ—­**(π—‡)μ„ μ„ νƒν•©λ‹λ‹¤.
1. Fabric μ©λ‰μ΄ ν¬ν•¨λ λΌμ΄μ„ μ¤ λ¨λ“(ν‰κ°€ν, ν”„λ¦¬λ―Έμ—„ λλ” Fabric)λ¥Ό μ„ νƒν•μ—¬ μ›ν•λ” μ΄λ¦„μΌλ΅ **μƒ μ‘μ—… μμ—­**μ„ λ§λ“­λ‹λ‹¤.
1. μƒ μ‘μ—… μμ—­μ΄ μ—΄λ¦¬λ©΄ λΉ„μ–΄ μμ–΄μ•Ό ν•©λ‹λ‹¤.

    ![λΉ Fabric μ‘μ—… μμ—­μ ν™”λ©΄ κ·Έλ¦Ό.](Images/workspace-empty.jpg)

## λ μ΄ν¬ν•μ°μ¤ λ§λ“¤κΈ° λ° λ°μ΄ν„° μ—…λ΅λ“

μ΄μ  μ‘μ—… μμ—­μ΄ μƒκ²Όλ‹¤λ©΄ λ μ΄ν¬ν•μ°μ¤λ¥Ό λ§λ“¤μ–΄ λ°μ΄ν„°λ¥Ό μ—…λ΅λ“ν•  μ°¨λ΅€μ…λ‹λ‹¤.

1. **Synapse Data Engineering** ν™νμ΄μ§€μ—μ„ μ›ν•λ” μ΄λ¦„μΌλ΅ μƒ **λ μ΄ν¬ν•μ°μ¤**λ¥Ό λ§λ“­λ‹λ‹¤. 
1. λ°μ΄ν„°λ¥Ό μμ§‘ν•λ” λ°©λ²•μ—λ” μ—¬λ¬ κ°€μ§€κ°€ μμ§€λ§ μ΄ μ—°μµμ—μ„λ” ν…μ¤νΈ νμΌμ„ λ΅μ»¬ μ»΄ν“¨ν„°(λλ” ν•΄λ‹Ήν•λ” κ²½μ° λ© VM)μ— λ‹¤μ΄λ΅λ“ν• λ‹¤μ λ μ΄ν¬ν•μ°μ¤μ— μ—…λ΅λ“ν•©λ‹λ‹¤. https://github.com/MicrosoftLearning/dp-data/raw/main/products.csvμ—μ„ [λ°μ΄ν„° νμΌ](https://github.com/MicrosoftLearning/dp-data/raw/main/products.csv)μ„ λ‹¤μ΄λ΅λ“ν•μ—¬ *products.csv*λ΅ μ €μ¥ν•©λ‹λ‹¤.
1.  λ μ΄ν¬ν•μ°μ¤κ°€ ν¬ν•¨λ μ›Ή λΈλΌμ°μ € νƒ­μΌλ΅ λμ•„κ°€μ„ νƒμƒ‰κΈ° μ°½μ **νμΌ** ν΄λ” μ†μ— μλ” ... λ©”λ‰΄λ¥Ό μ„ νƒν•©λ‹λ‹¤.  *products*λΌλ” **μƒ ν•μ„ ν΄λ”**λ¥Ό λ§λ“­λ‹λ‹¤.
1.  products ν΄λ”μ ... λ©”λ‰΄λ¥Ό ν†µν•΄ λ΅μ»¬ μ»΄ν“¨ν„°(λ‚ ν•΄λ‹Ή μ‹ λ© VM)μ—μ„ *products.csv* νμΌμ„ **μ—…λ΅λ“**ν•©λ‹λ‹¤.
1.  νμΌμ„ μ—…λ΅λ“ν• ν›„ **products** ν΄λ”λ¥Ό μ„ νƒν•μ—¬ μ—¬κΈ°μ— λ‚μ¨ λ€λ΅ νμΌμ΄ μ—…λ΅λ“λμ—λ”μ§€ ν™•μΈν•©λ‹λ‹¤.

    ![λ μ΄ν¬ν•μ°μ¤μ— μ—…λ΅λ“λ products.csvμ ν™”λ©΄ κ·Έλ¦Ό.](Images/upload-products.jpg)
  
## DataFrameμ—μ„ λ°μ΄ν„° νƒμƒ‰

1.  **μƒ Notebook**μ„ λ§λ“­λ‹λ‹¤. λ‡ μ΄ ν›„μ— λ‹¨μΌ μ…€μ΄ ν¬ν•¨λ μƒ Notebookμ΄ μ—΄λ¦½λ‹λ‹¤. Notebookμ€ μ½”λ“ λλ” markdown(μ„μ‹μ΄ μ§€μ •λ ν…μ¤νΈ)μ„ ν¬ν•¨ν•  μ μλ” ν•λ‚ μ΄μƒμ μ…€λ΅ κµ¬μ„±λ©λ‹λ‹¤.
2.  μ²« λ²μ§Έ μ…€(ν„μ¬ μ½”λ“ μ…€)μ„ μ„ νƒν• λ‹¤μ μ¤λ¥Έμ½ μ„μ— μλ” λ„κµ¬ λ¨μμ—μ„ **Mβ†“** λ²„νΌμ„ μ‚¬μ©ν•μ—¬ μ…€μ„ Markdown μ…€λ΅ λ³€ν™ν•©λ‹λ‹¤. κ·Έλ¬λ©΄ μ…€μ— ν¬ν•¨λ ν…μ¤νΈκ°€ μ„μ‹μ΄ μ§€μ •λ ν…μ¤νΈλ΅ ν‘μ‹λ©λ‹λ‹¤. Markdown μ…€μ„ μ‚¬μ©ν•μ—¬ μ½”λ“μ— λ€ν•΄ μ„¤λ…ν•λ” μ •λ³΄λ¥Ό μ…λ ¥ν•©λ‹λ‹¤.
3.  π–‰(νΈμ§‘) λ²„νΌμ„ μ‚¬μ©ν•μ—¬ μ…€μ„ νΈμ§‘ λ¨λ“λ΅ μ „ν™ν• ν›„ λ‹¤μκ³Ό κ°™μ΄ Markdownμ„ νΈμ§‘ν•©λ‹λ‹¤.

    ```markdown
    # Delta Lake tables 
    Use this notebook to explore Delta Lake functionality 
    ```

4. νΈμ§‘μ„ μ¤‘μ§€ν•κ³  λ λ”λ§λ markdownμ„ λ³΄λ ¤λ©΄ Notebookμ μ…€ μ™Έλ¶€ μ•„λ¬΄ κ³³μ΄λ‚ ν΄λ¦­ν•©λ‹λ‹¤.
5. μƒ μ½”λ“ μ…€μ„ μ¶”κ°€ν•κ³  λ‹¤μ μ½”λ“λ¥Ό μ¶”κ°€ν•μ—¬ μ •μλ μ¤ν‚¤λ§λ¥Ό μ‚¬μ©ν•μ—¬ μ ν’ λ°μ΄ν„°λ¥Ό DataFrameμΌλ΅ μ½μ–΄ μµλ‹λ‹¤.

    ```python
    from pyspark.sql.types import StructType, IntegerType, StringType, DoubleType

    # define the schema
    schema = StructType() \
    .add("ProductID", IntegerType(), True) \
    .add("ProductName", StringType(), True) \
    .add("Category", StringType(), True) \
    .add("ListPrice", DoubleType(), True)

    df = spark.read.format("csv").option("header","true").schema(schema).load("Files/products/products.csv")
    # df now is a Spark DataFrame containing CSV data from "Files/products/products.csv".
    display(df)
    ```

> [!TIP]
> νΌμΉ¨ λ‹¨μ¶” Β« μ•„μ΄μ½μ„ μ‚¬μ©ν•μ—¬ νƒμƒ‰κΈ° μ°½μ„ μ¨κΈ°κ±°λ‚ ν‘μ‹ν•©λ‹λ‹¤. μ΄λ ‡κ² ν•λ©΄ Notebook λλ” νμΌ μ¤‘ ν•λ‚μ— μ§‘μ¤‘ν•  μ μμµλ‹λ‹¤.

7. μ…€ μ™Όμ½μ **μ…€ μ‹¤ν–‰**(β–·) λ²„νΌμ„ μ‚¬μ©ν•μ—¬ μ‹¤ν–‰ν•©λ‹λ‹¤.

> [!NOTE]
> μ΄ Notebookμ—μ„ μ½”λ“λ¥Ό μ²μ μ‹¤ν–‰ν• κ²ƒμ΄λ―€λ΅ Spark μ„Έμ…μ„ μ‹μ‘ν•΄μ•Ό ν•©λ‹λ‹¤. μ΄λ” μ²« λ²μ§Έ μ‹¤ν–‰μ΄ μ™„λ£λλ” λ° 1λ¶„ μ •λ„ κ±Έλ¦΄ μ μμμ„ μλ―Έν•©λ‹λ‹¤. ν›„μ† μ‹¤ν–‰μ€ λ” λΉ¨λΌμ§ κ²ƒμ…λ‹λ‹¤.

8. μ…€ μ½”λ“κ°€ μ™„λ£λλ©΄ μ…€ μ•„λμ μ¶λ ¥μ„ κ²€ν† ν•©λ‹λ‹¤. λ‹¤μκ³Ό μ μ‚¬ν• μ¶λ ¥μ„ ν™•μΈν•  μ μμµλ‹λ‹¤.

    ![products.csv λ°μ΄ν„°μ ν™”λ©΄ κ·Έλ¦Ό.](Images/products-schema.jpg)
 
## λΈνƒ€ ν…μ΄λΈ” λ§λ“¤κΈ°

*saveAsTable* λ©”μ„λ“λ¥Ό μ‚¬μ©ν•μ—¬ DataFrameμ„ λΈνƒ€ ν…μ΄λΈ”λ΅ μ €μ¥ν•  μ μμµλ‹λ‹¤. Delta Lakeλ” κ΄€λ¦¬ ν…μ΄λΈ”κ³Ό μ™Έλ¶€ ν…μ΄λΈ” λ§λ“¤κΈ°λ¥Ό λ¨λ‘ μ§€μ›ν•©λ‹λ‹¤.

   * **κ΄€λ¦¬**ν• λΈνƒ€ ν…μ΄λΈ”μ€ Fabricμ΄ μ¤ν‚¤λ§ λ©”νƒ€λ°μ΄ν„°μ™€ λ°μ΄ν„° νμΌμ„ λ¨λ‘ κ΄€λ¦¬ν•λ―€λ΅ μ„±λ¥μ΄ ν–¥μƒλ©λ‹λ‹¤.
   * **μ™Έλ¶€** ν…μ΄λΈ”μ„ μ‚¬μ©ν•λ©΄ λ°μ΄ν„°λ¥Ό μ™Έλ¶€μ— μ €μ¥ν•  μ μμΌλ©° λ©”νƒ€λ°μ΄ν„°λ” Fabricμ—μ„ κ΄€λ¦¬ν•©λ‹λ‹¤.

### κ΄€λ¦¬λλ” ν…μ΄λΈ” λ§λ“¤κΈ°

**Tables** ν΄λ”μ— λ°μ΄ν„° νμΌμ΄ λ§λ“¤μ–΄μ§‘λ‹λ‹¤.

1. μ²« λ²μ§Έ μ½”λ“ μ…€μ—μ„ λ°ν™λ κ²°κ³Ό μ•„λμ—μ„ + μ½”λ“ μ•„μ΄μ½μ„ μ‚¬μ©ν•μ—¬ μƒ μ½”λ“ μ…€μ„ μ¶”κ°€ν•©λ‹λ‹¤.

> [!TIP]
> + μ½”λ“ μ•„μ΄μ½μ„ λ³΄λ ¤λ©΄ λ§μ°μ¤λ¥Ό ν„μ¬ μ…€μ μ¶λ ¥ λ°”λ΅ μ•„λ μ™Όμ½μΌλ΅ μ΄λ™ν•©λ‹λ‹¤. μ•„λ‹λ©΄ λ©”λ‰΄ λ¨μμ νΈμ§‘ νƒ­μ—μ„ **+ μ½”λ“ μ…€ μ¶”κ°€**λ¥Ό μ„ νƒν•©λ‹λ‹¤.

2. κ΄€λ¦¬ν• λΈνƒ€ ν…μ΄λΈ”μ„ λ§λ“¤κΈ° μ„ν•΄ μƒ μ…€μ„ μ¶”κ°€ν•κ³  λ‹¤μ μ½”λ“λ¥Ό μ…λ ¥ν• ν›„ μ…€μ„ μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    df.write.format("delta").saveAsTable("managed_products")
    ```

3.  λ μ΄ν¬ν•μ°μ¤ νƒμƒ‰κΈ° μ°½μ—μ„ Tables ν΄λ”λ¥Ό **μƒλ΅ κ³ μΉ¨**ν•κ³  Tables λ…Έλ“λ¥Ό ν™•μ¥ν•μ—¬ **managed_products** ν…μ΄λΈ”μ΄ λ§λ“¤μ–΄μ΅λ”μ§€ ν™•μΈν•©λ‹λ‹¤.

>[!NOTE]
> νμΌ μ΄λ¦„ μ†μ— μλ” μ‚Όκ°ν• μ•„μ΄μ½μ€ λΈνƒ€ ν…μ΄λΈ”μ„ λ‚νƒ€λƒ…λ‹λ‹¤.

κ΄€λ¦¬ν• ν…μ΄λΈ”μ νμΌμ€ λ μ΄ν¬ν•μ°μ¤μ **Tables** ν΄λ”μ— μ €μ¥λ©λ‹λ‹¤. ν…μ΄λΈ”μ— λ€ν• Parquet νμΌκ³Ό delta_log ν΄λ”κ°€ μ €μ¥λμ–΄ μλ” *managed_products*λΌλ” ν΄λ”κ°€ λ§λ“¤μ–΄μ΅μµλ‹λ‹¤.

### μ™Έλ¶€ ν…μ΄λΈ” λ§λ“¤κΈ°

λ μ΄ν¬ν•μ°μ¤κ°€ μ•„λ‹ λ‹¤λ¥Έ κ³³μ— μ €μ¥ν•  μ μλ” μ™Έλ¶€ ν…μ΄λΈ”μ„ λ§λ“¤ μλ„ μμΌλ©°, μ΄ κ²½μ° μ¤ν‚¤λ§ λ©”νƒ€λ°μ΄ν„°λ” λ μ΄ν¬ν•μ°μ¤μ— μ €μ¥λ©λ‹λ‹¤.

1.  Lakehouse νƒμƒ‰κΈ° μ°½μ ... λ©”λ‰΄λ¥Ό **Files** ν΄λ”μ— λ€ν•΄ μ„ νƒν•κ³  **ABFS κ²½λ΅ λ³µμ‚¬**λ¥Ό μ„ νƒν•©λ‹λ‹¤. ABFS κ²½λ΅λ” λ μ΄ν¬ν•μ°μ¤ Files ν΄λ”μ— λ€ν• μ •κ·ν™”λ κ²½λ΅μ…λ‹λ‹¤.

2.  μƒ μ½”λ“ μ…€μ— ABFS κ²½λ΅λ¥Ό λ¶™μ—¬λ„£μµλ‹λ‹¤. λ‹¤μ μ½”λ“λ¥Ό μ¶”κ°€ν•κ³  μλΌλ‚΄κΈ° λ° λ¶™μ—¬λ„£κΈ°λ¥Ό μ‚¬μ©ν•μ—¬ μ½”λ“μ μ¬λ°”λ¥Έ μ„μΉμ— abfs_pathλ¥Ό μ‚½μ…ν•©λ‹λ‹¤.

    ```python
    df.write.format("delta").saveAsTable("external_products", path="abfs_path/external_products")
    ```

3. μ „μ²΄ κ²½λ΅λ” λ‹¤μκ³Ό μ μ‚¬ν•΄μ•Ό ν•©λ‹λ‹¤.

    ```python
    abfss://workspace@tenant-onelake.dfs.fabric.microsoft.com/lakehousename.Lakehouse/Files/external_products
    ```

4. μ…€μ„ **μ‹¤ν–‰** ν•μ—¬ DataFrameμ„ Files/external_products ν΄λ”μ— μ™Έλ¶€ ν…μ΄λΈ”λ΅ μ €μ¥ν•©λ‹λ‹¤.

5.  λ μ΄ν¬ν•μ°μ¤ νƒμƒ‰κΈ° μ°½μ—μ„ Tables ν΄λ”λ¥Ό **μƒλ΅ κ³ μΉ¨**ν•κ³  Tables λ…Έλ“λ¥Ό ν™•μ¥ν•μ—¬ μ¤ν‚¤λ§ λ©”νƒ€λ°μ΄ν„°λ¥Ό ν¬ν•¨ν•λ” external_products ν…μ΄λΈ”μ΄ λ§λ“¤μ–΄μ΅λ”μ§€ ν™•μΈν•©λ‹λ‹¤.

6.  Lakehouse νƒμƒ‰κΈ° μ°½μ ... λ©”λ‰΄λ¥Ό Files ν΄λ”μ— λ€ν•΄ μ„ νƒν•κ³  **μƒλ΅ κ³ μΉ¨**μ„ μ„ νƒν•©λ‹λ‹¤. κ·Έλ° λ‹¤μ Files λ…Έλ“λ¥Ό ν™•μ¥ν•κ³  ν…μ΄λΈ”μ λ°μ΄ν„° νμΌμ— λ€ν•΄ external_products ν΄λ”κ°€ λ§λ“¤μ–΄μ΅λ”μ§€ ν™•μΈν•©λ‹λ‹¤.

### κ΄€λ¦¬ ν…μ΄λΈ”κ³Ό μ™Έλ¶€ ν…μ΄λΈ” λΉ„κµ

%%sql λ§¤μ§ λ…λ Ήμ„ μ‚¬μ©ν•μ—¬ κ΄€λ¦¬ν• ν…μ΄λΈ”κ³Ό μ™Έλ¶€ ν…μ΄λΈ”μ μ°¨μ΄μ μ„ μ‚΄ν΄λ³΄κ² μµλ‹λ‹¤.

1. μƒ μ½”λ“ μ…€μ—μ„ λ‹¤μ μ½”λ“λ¥Ό μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    %%sql
    DESCRIBE FORMATTED managed_products;
    ```

2. κ²°κ³Όμ—μ„ ν…μ΄λΈ”μ μ„μΉ μ†μ„±μ„ λ΄…λ‹λ‹¤. λ°μ΄ν„° ν•μ‹ μ—΄μ—μ„ μ„μΉ κ°’μ„ ν΄λ¦­ν•μ—¬ μ „μ²΄ κ²½λ΅λ¥Ό ν™•μΈν•©λ‹λ‹¤. OneLake μ¤ν† λ¦¬μ§€ μ„μΉλ” /Tables/managed_productsλ΅ λλ‚©λ‹λ‹¤.

3. μ—¬κΈ°μ— λ‚μ¤λ” λ€λ΅ external_products ν…μ΄λΈ”μ μ„Έλ¶€ μ •λ³΄λ¥Ό ν‘μ‹ν•λ„λ΅ DESCRIBE λ…λ Ήμ„ μμ •ν•©λ‹λ‹¤.

    ```python
    %%sql
    DESCRIBE FORMATTED external_products;
    ```

4. μ…€μ„ μ‹¤ν–‰ν•κ³  κ²°κ³Όμ—μ„ ν…μ΄λΈ”μ μ„μΉ μ†μ„±μ„ λ΄…λ‹λ‹¤. λ°μ΄ν„° ν•μ‹ μ—΄μ„ ν™•μ¥ν•μ—¬ μ „μ²΄ κ²½λ΅λ¥Ό ν™•μΈν•κ³  OneLake μ¤ν† λ¦¬μ§€ μ„μΉκ°€ /Files/external_productsλ΅ λλ‚λ”μ§€ ν™•μΈν•©λ‹λ‹¤.

5. μƒ μ½”λ“ μ…€μ—μ„ λ‹¤μ μ½”λ“λ¥Ό μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    %%sql
    DROP TABLE managed_products;
    DROP TABLE external_products;
    ```

6. Lakehouse νƒμƒ‰κΈ° μ°½μ—μ„ Tables ν΄λ”λ¥Ό **μƒλ΅ κ³ μΉ¨**ν•κ³  Tables λ…Έλ“μ λ©λ΅μ— ν…μ΄λΈ”μ΄ μ—†λ”μ§€ ν™•μΈν•©λ‹λ‹¤.
7.  λ μ΄ν¬ν•μ°μ¤ νƒμƒ‰κΈ° μ°½μ—μ„ Files ν΄λ”λ¥Ό **μƒλ΅ κ³ μΉ¨**ν•κ³  external_products νμΌμ΄ μ‚­μ λμ§€ *μ•μ•λ”μ§€* ν™•μΈν•©λ‹λ‹¤. Parquet λ°μ΄ν„° νμΌ λ° _delta_log ν΄λ”λ¥Ό λ³΄λ ¤λ©΄ μ΄ ν΄λ”λ¥Ό μ„ νƒν•©λ‹λ‹¤. 

μ™Έλ¶€ ν…μ΄λΈ”μ λ©”νƒ€λ°μ΄ν„°κ°€ μ‚­μ λμ—μ§€λ§ νμΌμ€ μν–¥μ„ λ°›μ§€ μ•μ•μµλ‹λ‹¤.

## SQLμ„ μ‚¬μ©ν•μ—¬ λΈνƒ€ ν…μ΄λΈ” λ§λ“¤κΈ°

μ΄μ  %%sql λ§¤μ§ λ…λ Ήμ„ μ‚¬μ©ν•μ—¬ λΈνƒ€ ν…μ΄λΈ”μ„ λ§λ“¤μ–΄ λ³΄κ² μµλ‹λ‹¤. 

1. λ‹¤λ¥Έ μ½”λ“ μ…€μ„ μ¶”κ°€ν•κ³  λ‹¤μ μ½”λ“λ¥Ό μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    %%sql
    CREATE TABLE products
    USING DELTA
    LOCATION 'Files/external_products';
    ```

2. Lakehouse νƒμƒ‰κΈ° μ°½μ ... **Tables** ν΄λ”μ ... λ©”λ‰΄μ—μ„ **μƒλ΅ κ³ μΉ¨**μ„ μ„ νƒν•©λ‹λ‹¤. κ·Έλ° λ‹¤μ Tables λ…Έλ“λ¥Ό ν™•μ¥ν•μ—¬ λ©λ΅μ— *products*λΌλ” μƒ ν…μ΄λΈ”μ΄ μλ”μ§€ ν™•μΈν•©λ‹λ‹¤. κ·Έλ° λ‹¤μ ν…μ΄λΈ”μ„ ν™•μ¥ν•μ—¬ μ¤ν‚¤λ§λ¥Ό λ΄…λ‹λ‹¤.

3. λ‹¤λ¥Έ μ½”λ“ μ…€μ„ μ¶”κ°€ν•κ³  λ‹¤μ μ½”λ“λ¥Ό μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    %%sql
    SELECT * FROM products;
    ```

## ν…μ΄λΈ” λ²„μ „ κ΄€λ¦¬ μ‚΄ν΄λ³΄κΈ°

λΈνƒ€ ν…μ΄λΈ”μ νΈλμ­μ… κΈ°λ΅μ€ delta_log ν΄λ”μ JSON νμΌμ— μ €μ¥λ©λ‹λ‹¤. μ΄ νΈλμ­μ… λ΅κ·Έλ¥Ό μ‚¬μ©ν•μ—¬ λ°μ΄ν„° λ²„μ „ κ΄€λ¦¬λ¥Ό κ΄€λ¦¬ν•  μ μμµλ‹λ‹¤.

1.  Notebookμ— μƒ μ½”λ“ μ…€μ„ μ¶”κ°€ν•κ³  μ‚°μ•… μμ „κ±° κ°€κ²©μ„ 10% μΈν•ν•λ” λ‹¤μ μ½”λ“λ¥Ό μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    %%sql
    UPDATE products
    SET ListPrice = ListPrice * 0.9
    WHERE Category = 'Mountain Bikes';
    ```

2. λ‹¤λ¥Έ μ½”λ“ μ…€μ„ μ¶”κ°€ν•κ³  λ‹¤μ μ½”λ“λ¥Ό μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    %%sql
    DESCRIBE HISTORY products;
    ```

κ²°κ³Όμ—λ” ν…μ΄λΈ”μ— κΈ°λ΅λ νΈλμ­μ… λ‚΄μ—­μ΄ ν‘μ‹λ©λ‹λ‹¤.

3.  λ‹¤λ¥Έ μ½”λ“ μ…€μ„ μ¶”κ°€ν•κ³  λ‹¤μ μ½”λ“λ¥Ό μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    delta_table_path = 'Files/external_products'
    # Get the current data
    current_data = spark.read.format("delta").load(delta_table_path)
    display(current_data)

    # Get the version 0 data
    original_data = spark.read.format("delta").option("versionAsOf", 0).load(delta_table_path)
    display(original_data)
    ```

λ‘ κ°μ κ²°κ³Ό μ§‘ν•©μ΄ λ°ν™λ©λ‹λ‹¤. ν•λ‚λ” κ°€κ²© μΈν• μ΄ν›„μ λ°μ΄ν„°λ¥Ό ν¬ν•¨ν•κ³  λ‹¤λ¥Έ ν•λ‚λ” λ°μ΄ν„°μ μ›λ³Έ λ²„μ „μ„ λ³΄μ—¬ μ¤λ‹λ‹¤.

## SQL μΏΌλ¦¬λ¥Ό μ‚¬μ©ν•μ—¬ λΈνƒ€ ν…μ΄λΈ” λ°μ΄ν„° λ¶„μ„

SQL λ§¤μ§ λ…λ Ήμ„ μ‚¬μ©ν•λ©΄ Pyspark λ€μ‹  SQL κµ¬λ¬Έμ„ μ‚¬μ©ν•  μ μμµλ‹λ‹¤. μ—¬κΈ°μ„λ” `SELECT` λ¬Έμ„ μ‚¬μ©ν•μ—¬ μ ν’ ν…μ΄λΈ”λ΅ μ„μ‹ λ³΄κΈ°λ¥Ό λ§λ“¤μ–΄ λ³΄κ² μµλ‹λ‹¤.

1. μƒ μ½”λ“ μ…€μ„ μ¶”κ°€ν•κ³  λ‹¤μ μ½”λ“λ¥Ό μ‹¤ν–‰ν•μ—¬ μ„μ‹ λ³΄κΈ°λ¥Ό λ§λ“¤κ³  ν‘μ‹ν•©λ‹λ‹¤.

    ```python
    %%sql
    -- Create a temporary view
    CREATE OR REPLACE TEMPORARY VIEW products_view
    AS
        SELECT Category, COUNT(*) AS NumProducts, MIN(ListPrice) AS MinPrice, MAX(ListPrice) AS MaxPrice, AVG(ListPrice) AS AvgPrice
        FROM products
        GROUP BY Category;

    SELECT *
    FROM products_view
    ORDER BY Category;    
    ```

2. μƒ μ½”λ“ μ…€μ„ μ¶”κ°€ν•κ³  λ‹¤μ μ½”λ“λ¥Ό μ‹¤ν–‰ν•μ—¬ μƒμ„ 10κ° λ²”μ£Όλ¥Ό μ ν’ μλ³„λ΅ λ°ν™ν•©λ‹λ‹¤.

    ```python
    %%sql
    SELECT Category, NumProducts
    FROM products_view
    ORDER BY NumProducts DESC
    LIMIT 10;
    ```

3. λ°μ΄ν„°κ°€ λ°ν™λλ©΄ **μ°¨νΈ** λ³΄κΈ°λ¥Ό μ„ νƒν•μ—¬ κ°€λ΅ λ§‰λ€ν• μ°¨νΈλ¥Ό ν‘μ‹ν•©λ‹λ‹¤.

    ![SQL select λ¬Έ λ° κ²°κ³Όμ ν™”λ©΄ κ·Έλ¦Ό.](Images/sql-select.jpg)

λλ” PySparkλ¥Ό μ‚¬μ©ν•μ—¬ SQL μΏΌλ¦¬λ¥Ό μ‹¤ν–‰ν•  μ μμµλ‹λ‹¤.

4. μƒ μ½”λ“ μ…€μ„ μ¶”κ°€ν•κ³  λ‹¤μ μ½”λ“λ¥Ό μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    from pyspark.sql.functions import col, desc

    df_products = spark.sql("SELECT Category, MinPrice, MaxPrice, AvgPrice FROM products_view").orderBy(col("AvgPrice").desc())
    display(df_products.limit(6))
    ```

## μ¤νΈλ¦¬λ° λ°μ΄ν„°μ— λΈνƒ€ ν…μ΄λΈ” μ‚¬μ©

Delta Lakeλ” μ¤νΈλ¦¬λ° λ°μ΄ν„°λ¥Ό μ§€μ›ν•©λ‹λ‹¤. λΈνƒ€ ν…μ΄λΈ”μ€ Spark κµ¬μ΅°μ  μ¤νΈλ¦¬λ° APIλ¥Ό μ‚¬μ©ν•μ—¬ μƒμ„±λ λ°μ΄ν„° μ¤νΈλ¦Όμ μ‹±ν¬ λλ” μ›λ³ΈμΌ μ μμµλ‹λ‹¤. μ΄ μμ μ—μ„λ” μ‹λ®¬λ μ΄μ…λ IoT(μ‚¬λ¬Ό μΈν„°λ„·) μ‹λ‚λ¦¬μ¤μ—μ„ λΈνƒ€ ν…μ΄λΈ”μ„ μΌλ¶€ μ¤νΈλ¦¬λ° λ°μ΄ν„°μ μ‹±ν¬λ΅ μ‚¬μ©ν•΄ λ³΄κ² μµλ‹λ‹¤.

1.  μƒ μ½”λ“ μ…€μ„ μ¶”κ°€ν•κ³  λ‹¤μ μ½”λ“λ¥Ό μ¶”κ°€ λ° μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    from notebookutils import mssparkutils
    from pyspark.sql.types import *
    from pyspark.sql.functions import *

    # Create a folder
    inputPath = 'Files/data/'
    mssparkutils.fs.mkdirs(inputPath)

    # Create a stream that reads data from the folder, using a JSON schema
    jsonSchema = StructType([
    StructField("device", StringType(), False),
    StructField("status", StringType(), False)
    ])
    iotstream = spark.readStream.schema(jsonSchema).option("maxFilesPerTrigger", 1).json(inputPath)

    # Write some event data to the folder
    device_data = '''{"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev2","status":"error"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"error"}
    {"device":"Dev2","status":"ok"}
    {"device":"Dev2","status":"error"}
    {"device":"Dev1","status":"ok"}'''

    mssparkutils.fs.put(inputPath + "data.txt", device_data, True)

    print("Source stream created...")
    ```

*μ›λ³Έ μ¤νΈλ¦Ό λ§λ“¤κΈ° μ™„λ£...* λ©”μ‹μ§€κ°€ ν‘μ‹λλ”μ§€ ν™•μΈν•©λ‹λ‹¤. λ°©κΈ μ‹¤ν–‰ν• μ½”λ“λ” κ°€μƒμ IoT λ””λ°”μ΄μ¤μ νλ…κ°’μ„ λ‚νƒ€λ‚΄λ” μΌλ¶€ λ°μ΄ν„°κ°€ μ €μ¥λ ν΄λ”λ¥Ό κΈ°λ°μΌλ΅ μ¤νΈλ¦¬λ° λ°μ΄ν„° μ›λ³Έμ„ λ§λ“¤μ—μµλ‹λ‹¤.

2. μƒ μ½”λ“ μ…€μ—μ„ λ‹¤μ μ½”λ“λ¥Ό μ¶”κ°€ν•κ³  μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    # Write the stream to a delta table
    delta_stream_table_path = 'Tables/iotdevicedata'
    checkpointpath = 'Files/delta/checkpoint'
    deltastream = iotstream.writeStream.format("delta").option("checkpointLocation", checkpointpath).start(delta_stream_table_path)
    print("Streaming to delta sink...")
    ```

μ΄ μ½”λ“λ” μ¤νΈλ¦¬λ° λ””λ°”μ΄μ¤ λ°μ΄ν„°λ¥Ό λΈνƒ€ ν•μ‹μΌλ΅ iotdevicedataλΌλ” ν΄λ”μ— μ‘μ„±ν•©λ‹λ‹¤. ν΄λ” μ„μΉμ— λ€ν• κ²½λ΅κ°€ Tables ν΄λ”μ— μμΌλ―€λ΅ ν•΄λ‹Ή ν΄λ”μ— λ€ν• ν…μ΄λΈ”μ΄ μλ™μΌλ΅ λ§λ“¤μ–΄μ§‘λ‹λ‹¤.

3. μƒ μ½”λ“ μ…€μ—μ„ λ‹¤μ μ½”λ“λ¥Ό μ¶”κ°€ν•κ³  μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    %%sql
    SELECT * FROM IotDeviceData;
    ```

μ΄ μ½”λ“λ” μ¤νΈλ¦¬λ° μ›λ³Έμ λ””λ°”μ΄μ¤ λ°μ΄ν„°λ¥Ό ν¬ν•¨ν•λ” IotDeviceData ν…μ΄λΈ”μ„ μΏΌλ¦¬ν•©λ‹λ‹¤.

4. μƒ μ½”λ“ μ…€μ—μ„ λ‹¤μ μ½”λ“λ¥Ό μ¶”κ°€ν•κ³  μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    # Add more data to the source stream
    more_data = '''{"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"ok"}
    {"device":"Dev1","status":"error"}
    {"device":"Dev2","status":"error"}
    {"device":"Dev1","status":"ok"}'''

    mssparkutils.fs.put(inputPath + "more-data.txt", more_data, True)
    ```

μ΄ μ½”λ“λ” μ¤νΈλ¦¬λ° μ›λ³Έμ— λ” λ§μ€ κ°€μƒ λ””λ°”μ΄μ¤ λ°μ΄ν„°λ¥Ό μ‘μ„±ν•©λ‹λ‹¤.

5. λ‹¤μ μ½”λ“κ°€ ν¬ν•¨λ μ…€μ„ λ‹¤μ‹ μ‹¤ν–‰ν•©λ‹λ‹¤.

    ```python
    %%sql
    SELECT * FROM IotDeviceData;
    ```

μ΄ μ½”λ“λ” μ΄μ  μ¤νΈλ¦¬λ° μ›λ³Έμ— μ¶”κ°€λ μ¶”κ°€ λ°μ΄ν„°λ¥Ό ν¬ν•¨ν•΄μ•Ό ν•λ” IotDeviceData ν…μ΄λΈ”μ„ λ‹¤μ‹ μΏΌλ¦¬ν•©λ‹λ‹¤.

6. μƒ μ½”λ“ μ…€μ—μ„ μ¤νΈλ¦Όμ„ μ¤‘μ§€ν•κ³  μ…€μ„ μ‹¤ν–‰ν•λ” μ½”λ“λ¥Ό μ¶”κ°€ν•©λ‹λ‹¤.

    ```python
    deltastream.stop()
    ```

## λ¦¬μ†μ¤ μ •λ¦¬

μ΄ μ—°μµμ—μ„λ” Microsoft Fabricμ—μ„ λΈνƒ€ ν…μ΄λΈ”μ„ μ‚¬μ©ν•μ—¬ μ‘μ—…ν•λ” λ°©λ²•μ„ μ•μ•„λ³΄μ•μµλ‹λ‹¤.

λ μ΄ν¬ν•μ°μ¤ νƒμƒ‰μ„ λ§μ³¤λ‹¤λ©΄ μ΄ μ—°μµμ„ μ„ν•΄ λ§λ“  μ‘μ—… μμ—­μ„ μ‚­μ ν•΄λ„ λ©λ‹λ‹¤.

1. μ™Όμ½ λ§‰λ€μ—μ„ μ‘μ—… μμ—­μ μ•„μ΄μ½μ„ μ„ νƒν•μ—¬ ν¬ν•¨λ λ¨λ“  ν•­λ©μ„ λ΄…λ‹λ‹¤.
2. λ„κµ¬ λ¨μμ β€¦ λ©”λ‰΄μ—μ„ **μ‘μ—… μμ—­ μ„¤μ •**μ„ μ„ νƒν•©λ‹λ‹¤.
3. μΌλ° μ„Ήμ…μ—μ„ **μ΄ μ‘μ—… μμ—­ μ κ±°**λ¥Ό μ„ νƒν•©λ‹λ‹¤.
